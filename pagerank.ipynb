{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20478714, 0.29521286, 0.29521286, 0.20478714])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_pagerank(G, alpha=0.85, q=None, max_iter=100, tol=1.0e-6):\n",
    "    \"\"\"\n",
    "    Compute the PageRank of each node in the graph G using the power method.\n",
    "\n",
    "    :param G: 2D numpy array representing the adjacency matrix of the graph\n",
    "    :param alpha: Damping factor for the random walk\n",
    "    :param q: Probability distribution for random jumps (uniform by default)\n",
    "    :param max_iter: Maximum number of iterations for the power method\n",
    "    :param tol: Tolerance for convergence\n",
    "    :return: 1D numpy array containing the PageRank of each node\n",
    "    \"\"\"\n",
    "    n = G.shape[0]  # Number of nodes\n",
    "\n",
    "    # If q is not provided, use a uniform distribution\n",
    "    if q is None:\n",
    "        q = np.ones(n) / n\n",
    "\n",
    "    # Initialize PageRank vector\n",
    "    p = np.ones(n) / n\n",
    "\n",
    "    # Normalize rows of G to represent probabilities\n",
    "    row_sums = G.sum(axis=1)\n",
    "    G_normalized = G / row_sums[:, np.newaxis]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        p_new = alpha * G_normalized.T.dot(p) + (1 - alpha) * q\n",
    "\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(p_new - p, ord=1) <= tol:\n",
    "            break\n",
    "\n",
    "        p = p_new\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "# Example graph (as an adjacency matrix)\n",
    "# A simple graph with 4 nodes\n",
    "G = np.array([\n",
    "    [0, 1, 1, 0],\n",
    "    [1, 0, 1, 1],\n",
    "    [1, 1, 0, 1],\n",
    "    [0, 1, 1, 0]\n",
    "], dtype=float)\n",
    "\n",
    "# Compute PageRank\n",
    "pagerank = compute_pagerank(G)\n",
    "pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22867099, 0.2944073 , 0.31081249, 0.16610923])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_optimized_pagerank(G, alpha=0.85, q=None, max_iter=100, tol=1.0e-6,\n",
    "                               incoming_link_weight=1.0, keyword_weight=1.0,\n",
    "                               outgoing_link_weight=1.0, link_quality_weight=1.0):\n",
    "    \"\"\"\n",
    "    Compute the optimized PageRank of each node in the graph G using the power method,\n",
    "    considering additional factors like incoming links, keywords, outgoing links, and link quality.\n",
    "\n",
    "    :param G: 2D numpy array representing the adjusted adjacency matrix of the graph with additional factors\n",
    "    :param alpha: Damping factor for the random walk\n",
    "    :param q: Probability distribution for random jumps (uniform by default)\n",
    "    :param max_iter: Maximum number of iterations for the power method\n",
    "    :param tol: Tolerance for convergence\n",
    "    :param incoming_link_weight: Weight factor for incoming links\n",
    "    :param keyword_weight: Weight factor for keyword relevance\n",
    "    :param outgoing_link_weight: Weight factor for outgoing links\n",
    "    :param link_quality_weight: Weight factor for link quality\n",
    "    :return: 1D numpy array containing the PageRank of each node\n",
    "    \"\"\"\n",
    "    n = G.shape[0]  # Number of nodes\n",
    "\n",
    "    # If q is not provided, use a uniform distribution\n",
    "    if q is None:\n",
    "        q = np.ones(n) / n\n",
    "\n",
    "    # Adjust weights in the adjacency matrix\n",
    "    adjusted_G = G.copy()\n",
    "    adjusted_G *= incoming_link_weight\n",
    "    adjusted_G *= keyword_weight\n",
    "    adjusted_G *= outgoing_link_weight\n",
    "    adjusted_G *= link_quality_weight\n",
    "\n",
    "    # Normalize rows of adjusted_G to represent probabilities\n",
    "    row_sums = adjusted_G.sum(axis=1)\n",
    "    G_normalized = adjusted_G / row_sums[:, np.newaxis]\n",
    "\n",
    "    # Initialize PageRank vector\n",
    "    p = np.ones(n) / n\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        p_new = alpha * G_normalized.T.dot(p) + (1 - alpha) * q\n",
    "\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(p_new - p, ord=1) <= tol:\n",
    "            break\n",
    "\n",
    "        p = p_new\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "# Example graph with additional factors (simplified for demonstration)\n",
    "# A simple graph with 4 nodes, weights are illustrative and not based on actual data\n",
    "G = np.array([\n",
    "    [0, 2, 3, 0],  # Incoming links, keywords, etc., for node 1\n",
    "    [2, 0, 1, 1],  # Node 2\n",
    "    [1, 2, 0, 1],  # Node 3\n",
    "    [0, 1, 2, 0]   # Node 4\n",
    "], dtype=float)\n",
    "\n",
    "# Compute optimized PageRank\n",
    "optimized_pagerank = compute_optimized_pagerank(G)\n",
    "optimized_pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24160266, 0.31018096, 0.25839734, 0.18981904])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_keyword_specific_pagerank(keyword_graphs, alpha=0.85, max_iter=100, tol=1.0e-6):\n",
    "    \"\"\"\n",
    "    Compute the keyword-specific PageRank for each keyword graph.\n",
    "\n",
    "    :param keyword_graphs: Dictionary of keyword graphs, where keys are keywords and values are adjacency matrices\n",
    "    :param alpha: Damping factor for the random walk\n",
    "    :param max_iter: Maximum number of iterations for the power method\n",
    "    :param tol: Tolerance for convergence\n",
    "    :return: Dictionary of PageRank vectors for each keyword\n",
    "    \"\"\"\n",
    "    keyword_pageranks = {}\n",
    "    for keyword, graph in keyword_graphs.items():\n",
    "        # Uniform distribution for q\n",
    "        q = np.ones(graph.shape[0]) / graph.shape[0]\n",
    "        pagerank = compute_pagerank(graph, alpha, q, max_iter, tol)\n",
    "        keyword_pageranks[keyword] = pagerank\n",
    "    return keyword_pageranks\n",
    "\n",
    "\n",
    "def aggregate_pageranks(keyword_pageranks, keyword_weights):\n",
    "    \"\"\"\n",
    "    Aggregate the keyword-specific PageRank vectors into a final PageRank vector.\n",
    "\n",
    "    :param keyword_pageranks: Dictionary of PageRank vectors for each keyword\n",
    "    :param keyword_weights: Dictionary of weights for each keyword\n",
    "    :return: Aggregated PageRank vector\n",
    "    \"\"\"\n",
    "    aggregated_pagerank = np.zeros_like(list(keyword_pageranks.values())[0])\n",
    "    for keyword, pagerank in keyword_pageranks.items():\n",
    "        # Default weight is 1 if not specified\n",
    "        weight = keyword_weights.get(keyword, 1)\n",
    "        aggregated_pagerank += weight * pagerank\n",
    "    aggregated_pagerank /= sum(keyword_weights.values())\n",
    "    return aggregated_pagerank\n",
    "\n",
    "\n",
    "# Example keyword-specific graphs (simplified for demonstration)\n",
    "keyword_graphs = {\n",
    "    \"keyword1\": np.array([\n",
    "        [0, 2, 0, 0],\n",
    "        [2, 0, 1, 0],\n",
    "        [0, 1, 0, 1],\n",
    "        [0, 0, 1, 0]\n",
    "    ], dtype=float),\n",
    "    \"keyword2\": np.array([\n",
    "        [0, 1, 1, 0],\n",
    "        [1, 0, 0, 1],\n",
    "        [1, 0, 0, 1],\n",
    "        [0, 1, 1, 0]\n",
    "    ], dtype=float)\n",
    "}\n",
    "\n",
    "# Example keyword weights\n",
    "keyword_weights = {\n",
    "    \"keyword1\": 0.6,\n",
    "    \"keyword2\": 0.4\n",
    "}\n",
    "\n",
    "# Compute keyword-specific PageRanks\n",
    "keyword_pageranks = compute_keyword_specific_pagerank(keyword_graphs)\n",
    "\n",
    "# Aggregate PageRanks\n",
    "aggregated_pagerank = aggregate_pageranks(keyword_pageranks, keyword_weights)\n",
    "aggregated_pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'strategy2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_advanced_pagerank(graphs, alpha=0.85, max_iter=100, tol=1.0e-6):\n",
    "    \"\"\"\n",
    "    Compute the advanced PageRank considering different strategies: link addition/removal, link quality adjustment, and keyword adjustment.\n",
    "\n",
    "    :param graphs: Dictionary of graphs for each strategy combination\n",
    "    :param alpha: Damping factor for the random walk\n",
    "    :param max_iter: Maximum number of iterations for the power method\n",
    "    :param tol: Tolerance for convergence\n",
    "    :return: Dictionary of PageRank vectors for each strategy\n",
    "    \"\"\"\n",
    "    strategy_pageranks = {}\n",
    "    for strategy, graph in graphs.items():\n",
    "        # Uniform distribution for q\n",
    "        q = np.ones(graph.shape[0]) / graph.shape[0]\n",
    "        pagerank = compute_pagerank(graph, alpha, q, max_iter, tol)\n",
    "        strategy_pageranks[strategy] = pagerank\n",
    "    return strategy_pageranks\n",
    "\n",
    "\n",
    "def evaluate_strategies(strategy_pageranks):\n",
    "    \"\"\"\n",
    "    Evaluate and compare the strategies to find the Nash Equilibrium.\n",
    "\n",
    "    :param strategy_pageranks: Dictionary of PageRank vectors for each strategy\n",
    "    :return: Strategy that yields the highest PageRank, indicating Nash Equilibrium\n",
    "    \"\"\"\n",
    "    best_strategy = None\n",
    "    best_pagerank = None\n",
    "\n",
    "    for strategy, pagerank in strategy_pageranks.items():\n",
    "        if best_pagerank is None or np.max(pagerank) > np.max(best_pagerank):\n",
    "            best_strategy = strategy\n",
    "            best_pagerank = pagerank\n",
    "\n",
    "    return best_strategy\n",
    "\n",
    "\n",
    "# Example: Different strategy graphs (simplified for demonstration)\n",
    "# Here, we consider different strategies as different graphs for simplicity\n",
    "# 更新后的示例策略图\n",
    "strategy_graphs = {\n",
    "    \"strategy1\": np.array([\n",
    "        [0, 2, 1, 0],\n",
    "        [2, 0, 3, 1],\n",
    "        [1, 3, 0, 2],\n",
    "        [0, 1, 2, 0]\n",
    "    ], dtype=float),\n",
    "    \"strategy2\": np.array([\n",
    "        [0, 1, 0, 1],\n",
    "        [1, 0, 2, 0],\n",
    "        [0, 2, 0, 3],\n",
    "        [1, 0, 3, 0]\n",
    "    ], dtype=float)\n",
    "    # 可以根据需要添加更多策略和相应的图\n",
    "}\n",
    "\n",
    "# 重新计算每种策略的PageRanks\n",
    "strategy_pageranks = compute_advanced_pagerank(strategy_graphs)\n",
    "\n",
    "# 重新评估策略以找到Nash Equilibrium\n",
    "nash_equilibrium_strategy = evaluate_strategies(strategy_pageranks)\n",
    "nash_equilibrium_strategy, strategy_pageranks[nash_equilibrium_strategy]\n",
    "\n",
    "\n",
    "# Compute PageRanks for each strategy\n",
    "strategy_pageranks = compute_advanced_pagerank(strategy_graphs)\n",
    "\n",
    "# Evaluate strategies to find Nash Equilibrium\n",
    "nash_equilibrium_strategy = evaluate_strategies(strategy_pageranks)\n",
    "nash_equilibrium_strategy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
