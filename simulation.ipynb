{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_sorted_values_descending(pi_T, pi_new):\n",
    "    pi_T_sorted_indices = np.argsort(-pi_T)\n",
    "    pi_new_sorted_indices = np.argsort(-pi_new)\n",
    "\n",
    "    print(\"pi_T:\")\n",
    "    for index, value in zip(pi_T_sorted_indices, pi_T[pi_T_sorted_indices]):\n",
    "        print(f\"Node{index + 1}: {value}\")\n",
    "\n",
    "    print(\"pi_new:\")\n",
    "    for index, value in zip(pi_new_sorted_indices, pi_new[pi_new_sorted_indices]):\n",
    "        print(f\"Node{index + 1}: {value}\")\n",
    "\n",
    "def compute_pagerank(G, alpha=0.85, q=None, max_iter=100, tol=1.0e-6):\n",
    "    \"\"\"\n",
    "    Compute the PageRank of each node in the graph G using the power method.\n",
    "\n",
    "    :param G: 2D numpy array representing the adjacency matrix of the graph\n",
    "    :param alpha: Damping factor for the random walk\n",
    "    :param q: Probability distribution for random jumps (uniform by default)\n",
    "    :param max_iter: Maximum number of iterations for the power method\n",
    "    :param tol: Tolerance for convergence\n",
    "    :return: 1D numpy array containing the PageRank of each node\n",
    "    \"\"\"\n",
    "    n = G.shape[0]  # Number of nodes\n",
    "\n",
    "    # If q is not provided, use a uniform distribution\n",
    "    if q is None:\n",
    "        q = np.ones(n) / n\n",
    "\n",
    "    # Initialize PageRank vector\n",
    "    p = np.ones(n) / n\n",
    "\n",
    "    # Normalize rows of G to represent probabilities\n",
    "    row_sums = G.sum(axis=1)\n",
    "    G_normalized = G / row_sums[:, np.newaxis]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        p_new = alpha * G_normalized.T.dot(p) + (1 - alpha) * q\n",
    "\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(p_new - p, ord=1) <= tol:\n",
    "            break\n",
    "\n",
    "        p = p_new\n",
    "\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank: [0.33961209 0.10216768 0.22802627 0.22802627 0.10216768]\n",
      "[4 1 3 3 1]\n",
      "[4 3 2 2 1]\n",
      "[0.5        0.25       0.33333333 0.33333333 0.25      ]\n",
      "pi_T:\n",
      "Node1: 0.33961209079305577\n",
      "Node3: 0.2280262745411698\n",
      "Node4: 0.2280262745411698\n",
      "Node2: 0.10216768006230231\n",
      "Node5: 0.10216768006230231\n",
      "pi_new:\n",
      "Node1: 1.8614769144520331\n",
      "Node2: 1.0799700626563706\n",
      "Node3: 1.063351231979778\n",
      "Node4: 0.9337567531831317\n",
      "Node5: 0.8543916738180523\n"
     ]
    }
   ],
   "source": [
    "# Adjacency matrix\n",
    "adjacency_matrix = np.array([\n",
    "    [0, 1, 1, 1, 1],\n",
    "    [1, 0, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "n = adjacency_matrix.shape[0]\n",
    "pi_T = compute_pagerank(adjacency_matrix)\n",
    "print(\"PageRank:\", pi_T)\n",
    "\n",
    "\n",
    "# L_w^{in}\n",
    "incoming_links = np.sum(adjacency_matrix, axis=0)\n",
    "outgoing_links = np.sum(adjacency_matrix, axis=1)\n",
    "\n",
    "print(incoming_links)\n",
    "print(outgoing_links)\n",
    "\n",
    "L_w_in = np.zeros(n)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if adjacency_matrix[j][i] == 1: #指向i的节点\n",
    "            L_w_in[i] += outgoing_links[j]\n",
    "    # print(incoming_links[i], L_w_in[i])\n",
    "    L_w_in[i] = incoming_links[i] / L_w_in[i]\n",
    "\n",
    "print(L_w_in)\n",
    "\n",
    "\n",
    "# N_k/N_T\n",
    "keyword_frequency = np.array([1.042, 1.032, 1.030, 1.023, 1.023])\n",
    "\n",
    "# T\n",
    "traffic = np.array([7400, 2500, 2400, 1600, 1100])\n",
    "T_min = np.min(traffic)\n",
    "T_max = np.max(traffic)\n",
    "T_hat = 0.1 + (traffic - T_min) / (T_max - T_min)\n",
    "\n",
    "pi_new = np.dot(pi_T, L_w_in) * (1 + keyword_frequency) + T_hat\n",
    "\n",
    "# print(pi_T)\n",
    "# print(pi_new)\n",
    "\n",
    "print_sorted_values_descending(pi_T, pi_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
