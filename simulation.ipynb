{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_pagerank(G, alpha=0.85, q=None, max_iter=100, tol=1.0e-6):\n",
    "    n = G.shape[0]\n",
    "    if q is None:\n",
    "        q = np.ones(n) / n\n",
    "    p = np.ones(n) / n\n",
    "    row_sums = G.sum(axis=1)\n",
    "    G_normalized = G / row_sums[:, np.newaxis]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        p_new = alpha * G_normalized.T.dot(p) + (1 - alpha) * q\n",
    "        if np.linalg.norm(p_new - p, ord=1) <= tol:\n",
    "            break\n",
    "\n",
    "        p = p_new\n",
    "\n",
    "    return p\n",
    "\n",
    "def compute_pagerank_matrix(adjacency_matrix, alpha=0.85, strategy_x=None):\n",
    "    \"\"\"\n",
    "    Computes the PageRank vector for an entire graph represented by an adjacency matrix.\n",
    "\n",
    "    :param adjacency_matrix: Adjacency matrix representing the graph.\n",
    "    :param alpha: Damping factor used in PageRank.\n",
    "    :param strategy_x: Strategy matrix indicating which edges are retained (1) or not (0).\n",
    "    :return: The PageRank vector for the entire graph.\n",
    "    \"\"\"\n",
    "    if strategy_x is None:\n",
    "        # If no strategy is provided, use the adjacency matrix itself\n",
    "        strategy_x = adjacency_matrix\n",
    "\n",
    "    n = adjacency_matrix.shape[0]  # Number of vertices\n",
    "\n",
    "    # Normalize the adjacency matrix to get the transition probability matrix\n",
    "    M = adjacency_matrix / np.sum(adjacency_matrix, axis=1, keepdims=True)\n",
    "    print(M)\n",
    "\n",
    "    # Apply strategy to the transition probability matrix\n",
    "    M = M * strategy_x\n",
    "\n",
    "    print(M)\n",
    "\n",
    "    # Initialize the PageRank vector with a uniform distribution\n",
    "    pi = np.ones(n) / n\n",
    "\n",
    "    # Compute the PageRank vector iteratively\n",
    "    for _ in range(1000):  # Hardcoded max_iter\n",
    "        new_pi = alpha * np.matmul(M, pi) + (1 - alpha) / n\n",
    "        if np.linalg.norm(new_pi - pi) < 1e-6:  # Hardcoded tolerance\n",
    "            break\n",
    "        pi = new_pi\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageRank: [0.33961209 0.10216768 0.22802627 0.22802627 0.10216768]\n",
      "[4 1 3 3 1]\n",
      "[4 3 2 2 1]\n",
      "[0.33961209 0.10216768 0.22802627 0.22802627 0.10216768]\n",
      "[1.44674394 0.3741234  0.46064699 0.3331308  0.1516713 ]\n"
     ]
    }
   ],
   "source": [
    "# Adjacency matrix\n",
    "adjacency_matrix = np.array([\n",
    "    [0, 1, 1, 1, 1],\n",
    "    [1, 0, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "n = adjacency_matrix.shape[0]\n",
    "pi_T = compute_pagerank(adjacency_matrix)\n",
    "print(\"PageRank:\", pi_T)\n",
    "\n",
    "\n",
    "# L_w^{in}\n",
    "incoming_links = np.sum(adjacency_matrix, axis=0)\n",
    "outgoing_links = np.sum(adjacency_matrix, axis=1)\n",
    "\n",
    "print(incoming_links)\n",
    "print(outgoing_links)\n",
    "\n",
    "L_w_in = np.zeros(n)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if adjacency_matrix[j][i] == 1:  # 指向i的节点\n",
    "            L_w_in[i] += outgoing_links[j]\n",
    "    # print(incoming_links[i], L_w_in[i])\n",
    "    L_w_in[i] = incoming_links[i] / L_w_in[i]\n",
    "\n",
    "# print(L_w_in)\n",
    "\n",
    "\n",
    "# N_k/N_T\n",
    "keyword_frequency = np.array([1.042, 1.032, 1.030, 1.023, 1.023])\n",
    "\n",
    "# T\n",
    "traffic = np.array([7400, 2500, 2400, 1600, 1100])\n",
    "T_min = np.min(traffic)\n",
    "T_max = np.max(traffic)\n",
    "T_hat = 0.1 + (traffic - T_min) / (T_max - T_min)\n",
    "\n",
    "pi_new = pi_T * L_w_in * (1 + keyword_frequency) + T_hat\n",
    "\n",
    "print(pi_T)\n",
    "print(pi_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
